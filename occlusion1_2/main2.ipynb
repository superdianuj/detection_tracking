{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from ultralytics import YOLO\n",
    "import supervision as sv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import os\n",
    "from matplotlib import rcParams\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "display.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_info(video_path):\n",
    "    \n",
    "    # Extracting information about the video\n",
    "    video_info = sv.VideoInfo.from_video_path(video_path)\n",
    "    width, height, fps, total_frames = video_info.width, video_info.height, video_info.fps, video_info.total_frames\n",
    "    \n",
    "    # Calculating the length of the video by dividing the total number of frames by the frame rate and rounding to the nearest second\n",
    "    video_length = timedelta(seconds = round(total_frames / fps))\n",
    "    \n",
    "    # Print out the video resolution, fps, and length u\n",
    "    print(f\"\\033[1mVideo Resolution:\\033[0m ({width}, {height})\")\n",
    "    print(f\"\\033[1mFPS:\\033[0m {fps}\")\n",
    "    print(f\"\\033[1mLength:\\033[0m {video_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mVideo Resolution:\u001b[0m (2592, 1944)\n",
      "\u001b[1mFPS:\u001b[0m 30\n",
      "\u001b[1mLength:\u001b[0m 0:00:24\n"
     ]
    }
   ],
   "source": [
    "get_video_info('ref_vid.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def person_count(source_path,line_start, line_end):\n",
    "   \n",
    "   # Load the pre-trained YOLO model\n",
    "   model = YOLO('yolov8x.pt')\n",
    "\n",
    "   # Create two points from the line_start and line_end coordinates\n",
    "   line_start = sv.Point(line_start[0], line_start[1])\n",
    "   line_end = sv.Point(line_end[0], line_end[1])\n",
    "   \n",
    "   # Create a line zone object from the two points\n",
    "   line_counter = sv.LineZone(line_start, line_end) \n",
    "   \n",
    "   # Create a line zone annotator object with specific thickness and text scale\n",
    "   line_annotator = sv.LineZoneAnnotator(thickness = 2,\n",
    "                                         text_thickness = 1,\n",
    "                                         text_scale = 0.5)\n",
    "   \n",
    "   # Create a box annotator object with specific thickness and text scale\n",
    "   box_annotator = sv.BoxAnnotator(thickness = 1,\n",
    "                                   text_thickness = 1,\n",
    "                                   text_scale = 0.5)\n",
    "   \n",
    "   # Extract information about the video from the given source path\n",
    "   video_info = sv.VideoInfo.from_video_path(source_path)\n",
    "\n",
    "   # Create a video out path by combining the destination path and the video name\n",
    "   video_name = os.path.splitext(os.path.basename(source_path))[0] + \".mp4\"\n",
    "   video_out_path = \"ref_vid_detected.mp4\"\n",
    "\n",
    "   # Create a video writer object for the output video\n",
    "   video_out = cv2.VideoWriter(video_out_path, cv2.VideoWriter_fourcc(*'mp4v'), video_info.fps, (video_info.width, video_info.height))\n",
    "\n",
    "   # Loop over each frame of the video and perform object detection and tracking\n",
    "   for result in model.track(source = source_path, tracker = 'botsort.yaml', conf=0.01, show=True, stream=True, agnostic_nms=True):\n",
    "        \n",
    "\n",
    "        \n",
    "      \n",
    "        # Get the original frame from the detection result\n",
    "        frame = result.orig_img\n",
    "        \n",
    "        # Convert the YOLO detection results to a Detections object\n",
    "        detections = sv.Detections.from_ultralytics(result)\n",
    "\n",
    "        if detections.tracker_id is not None:\n",
    "\n",
    "          detections.tracker_id = result.boxes.id.cpu().numpy().astype(int)\n",
    "\n",
    "          # Filter the detections\n",
    "          detections = detections[detections.class_id == 0]\n",
    "\n",
    "          # labels = [\n",
    "          #             f\"{model.model.names[class_id]} confidence:{confidence}\" \n",
    "          #             for _, _, confidence, class_id, _, _ in detections\n",
    "          #         ]\n",
    "\n",
    "          labels = [\n",
    "                      f\"{tracker_id} confidence:{confidence}\" \n",
    "                      for _, _, confidence, class_id, tracker_id, _ in detections\n",
    "                  ]\n",
    "\n",
    "          # Trigger the line counter to count any detections that intersect the line zone\n",
    "          line_counter.trigger(detections)\n",
    "      \n",
    "          # Annotate the frame with the line zone and any intersecting detections\n",
    "          line_annotator.annotate(frame, line_counter)\n",
    "\n",
    "          # Annotate the frame with bounding boxes and labels for all detections\n",
    "          frame = box_annotator.annotate(scene = frame,\n",
    "                                        detections = detections,\n",
    "                                        labels = labels)\n",
    "          \n",
    "\n",
    "          # Write the annotated frame to the output video\n",
    "          video_out.write(frame)\n",
    "  \n",
    "   # Release the video writer and clear the Jupyter Notebook output\n",
    "   video_out.release()\n",
    "   display.clear_output()\n",
    "\n",
    "\n",
    "# Performing vehicle count on the test video\n",
    "person_count(source_path = \"ref_vid.mp4\",\n",
    "              line_start = (337, 391),\n",
    "              line_end = (917, 387))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torcher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
