{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oyHUcn9qEyMb"
      },
      "outputs": [],
      "source": [
        "# Object Detecion\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "#plots\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "#basics\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Display image and videos\n",
        "import IPython\n",
        "from IPython.display import Video, display\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "import urllib.request\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cn_NQ6L9EyMc"
      },
      "outputs": [],
      "source": [
        "path = 'ref_vid.mp4'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jx4wlem6EyMd"
      },
      "outputs": [],
      "source": [
        "#loading a YOLO model\n",
        "model = YOLO('yolov8x.pt')\n",
        "\n",
        "#geting names from classes\n",
        "dict_classes = model.model.names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "X7RatOrrEyMe"
      },
      "outputs": [],
      "source": [
        "# Auxiliary functions\n",
        "def risize_frame(frame, scale_percent):\n",
        "    \"\"\"Function to resize an image in a percent scale\"\"\"\n",
        "    width = int(frame.shape[1] * scale_percent / 100)\n",
        "    height = int(frame.shape[0] * scale_percent / 100)\n",
        "    dim = (width, height)\n",
        "\n",
        "    # resize image\n",
        "    resized = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
        "    return resized\n",
        "\n",
        "\n",
        "\n",
        "def filter_tracks(centers, patience):\n",
        "    \"\"\"Function to filter track history\"\"\"\n",
        "    filter_dict = {}\n",
        "    for k, i in centers.items():\n",
        "        d_frames = i.items()\n",
        "        filter_dict[k] = dict(list(d_frames)[-patience:])\n",
        "\n",
        "    return filter_dict\n",
        "\n",
        "\n",
        "def update_tracking(centers_old,obj_center, thr_centers, lastKey, frame, frame_max):\n",
        "    \"\"\"Function to update track of objects\"\"\"\n",
        "    is_new = 0\n",
        "    lastpos = [(k, list(center.keys())[-1], list(center.values())[-1]) for k, center in centers_old.items()]\n",
        "    lastpos = [(i[0], i[2]) for i in lastpos if abs(i[1] - frame) <= frame_max]\n",
        "    # Calculating distance from existing centers points\n",
        "    previous_pos = [(k,obj_center) for k,centers in lastpos if (np.linalg.norm(np.array(centers) - np.array(obj_center)) < thr_centers)]\n",
        "    # if distance less than a threshold, it will update its positions\n",
        "    if previous_pos:\n",
        "        id_obj = previous_pos[0][0]\n",
        "        centers_old[id_obj][frame] = obj_center\n",
        "\n",
        "    # Else a new ID will be set to the given object\n",
        "    else:\n",
        "        if lastKey:\n",
        "            last = lastKey.split('D')[1]\n",
        "            id_obj = 'ID' + str(int(last)+1)\n",
        "        else:\n",
        "            id_obj = 'ID0'\n",
        "\n",
        "        is_new = 1\n",
        "        centers_old[id_obj] = {frame:obj_center}\n",
        "        lastKey = list(centers_old.keys())[-1]\n",
        "\n",
        "\n",
        "    return centers_old, id_obj, is_new, lastKey"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "1e2c01e9c1cb4978bc4990a2a71828ca",
            "9056a3f7b85049d1b8e00f1c22cef334",
            "2567e64471ca46dbb7a91c86062de2fa",
            "de99875491f24a59947d9f4e431410a7",
            "60cf70a9b5da4e1b99950825b01fe957",
            "818e1afafc214a31a013272e96717768",
            "80ded324aabe4dacbf266b18e39a01b4",
            "c4bdb2047a64445cba281e903c3f99f2",
            "a49e03283cbf4cb9bafbbff132476a48",
            "ec3965bff3ad48069a281d3b13e9a2af",
            "386dbcf420d44226a27fdd434e5820da"
          ]
        },
        "id": "H0lrIpqSEyMe",
        "outputId": "db5c773a-e3a9-4470-a542-8ba5fad74346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] - Verbose during Prediction: False\n",
            "[INFO] - Original Dim:  (2592, 1944)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16123580b9ab4543b3f60ede6d5f6ce6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/711 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "### Configurations\n",
        "#Verbose during prediction\n",
        "verbose = False\n",
        "# Scaling percentage of original frame\n",
        "scale_percent = 100\n",
        "# model confidence level\n",
        "conf_level = 0.8\n",
        "# Threshold of centers ( old\\new)\n",
        "thr_centers = 20\n",
        "#Number of max frames to consider a object lost\n",
        "frame_max = 5\n",
        "# Number of max tracked centers stored\n",
        "patience = 100\n",
        "# ROI area color transparency\n",
        "alpha = 0.1\n",
        "#-------------------------------------------------------\n",
        "# Reading video with cv2\n",
        "video = cv2.VideoCapture(path)\n",
        "\n",
        "# Objects to detect Yolo\n",
        "class_IDS = [0]\n",
        "# Auxiliary variables\n",
        "centers_old = {}\n",
        "\n",
        "obj_id = 0\n",
        "end = []\n",
        "frames_list = []\n",
        "count_p = 0\n",
        "lastKey = ''\n",
        "print(f'[INFO] - Verbose during Prediction: {verbose}')\n",
        "\n",
        "\n",
        "# Original informations of video\n",
        "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "fps = video.get(cv2.CAP_PROP_FPS)\n",
        "print('[INFO] - Original Dim: ', (width, height))\n",
        "\n",
        "# Scaling Video for better performance\n",
        "if scale_percent != 100:\n",
        "    print('[INFO] - Scaling change may cause errors in pixels lines ')\n",
        "    width = int(width * scale_percent / 100)\n",
        "    height = int(height * scale_percent / 100)\n",
        "    print('[INFO] - Dim Scaled: ', (width, height))\n",
        "\n",
        "\n",
        "#-------------------------------------------------------\n",
        "### Video output ####\n",
        "video_name = 'result.mp4'\n",
        "output_path = \"rep_\" + video_name\n",
        "tmp_output_path = \"tmp_\" + output_path\n",
        "VIDEO_CODEC = \"mp4v\"\n",
        "\n",
        "output_video = cv2.VideoWriter(tmp_output_path,\n",
        "                               cv2.VideoWriter_fourcc(*VIDEO_CODEC),\n",
        "                               fps, (width, height))\n",
        "\n",
        "\n",
        "#-------------------------------------------------------\n",
        "# Executing Recognition\n",
        "for i in tqdm(range(int(video.get(cv2.CAP_PROP_FRAME_COUNT)))):\n",
        "\n",
        "    # reading frame from video\n",
        "    _, frame = video.read()\n",
        "\n",
        "    #Applying resizing of read frame\n",
        "    frame  = risize_frame(frame, scale_percent)\n",
        "#     frame  = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "\n",
        "\n",
        "    area_roi = [np.array([ (1300, 200),(200,400),(400,800) ,(1250,800)], np.int32)]\n",
        "\n",
        "\n",
        "    #----------------------------------------------------------------------------------------------\n",
        "    # # # Original informations of video\n",
        "    # height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    # width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    # fps = video.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # # Scaling Video for better performance\n",
        "    # if scale_percent != 100:\n",
        "    #     print('[INFO] - Scaling change may cause errors in pixels lines ')\n",
        "    #     width = int(width * scale_percent / 100)\n",
        "    #     height = int(height * scale_percent / 100)\n",
        "\n",
        "    # # Setting the ROI to cover the whole frame\n",
        "    # area_roi = [np.array([(0, 0), (width, 0), (width, height), (0, height)], np.int32)]\n",
        "    #----------------------------------------------------------------------------------------------\n",
        "\n",
        "    # ROI = frame[5:1300, 5:1300]\n",
        "    ROI = frame\n",
        "\n",
        "\n",
        "    if verbose:\n",
        "        print('Dimension Scaled(frame): ', (frame.shape[1], frame.shape[0]))\n",
        "\n",
        "    # Getting predictions\n",
        "    y_hat = model.predict(ROI, conf = conf_level, classes = class_IDS, device = 0, verbose = False)\n",
        "\n",
        "\n",
        "    boxes_object = y_hat[0].cpu().boxes\n",
        "\n",
        "    # Extracting the relevant attributes\n",
        "    xyxy = boxes_object.xyxy  # Box coordinates in xyxy format\n",
        "    conf = boxes_object.conf  # Confidence scores\n",
        "    cls = boxes_object.cls    # Class labels\n",
        "    positions_frame = pd.DataFrame(xyxy, columns=['xmin', 'ymin', 'xmax', 'ymax'])\n",
        "    positions_frame['conf'] = conf\n",
        "    positions_frame['class'] = cls\n",
        "\n",
        "\n",
        "    # For each people, draw the bounding-box and counting each one the pass thought the ROI area\n",
        "    for ix, row in enumerate(positions_frame.iterrows()):\n",
        "        # Getting the coordinates of each vehicle (row)\n",
        "        xmin, ymin, xmax, ymax, confidence, category,  = row[1].astype('int')\n",
        "\n",
        "        # Calculating the center of the bounding-box\n",
        "        center_x, center_y = int(((xmax+xmin))/2), int((ymax+ ymin)/2)\n",
        "\n",
        "        #Updating the tracking for each object\n",
        "        centers_old, id_obj, is_new, lastKey = update_tracking(centers_old, (center_x, center_y), thr_centers, lastKey, i, frame_max)\n",
        "\n",
        "\n",
        "        #Updating people in roi\n",
        "        count_p+=is_new\n",
        "\n",
        "        # drawing center and bounding-box in the given frame\n",
        "        cv2.rectangle(ROI, (xmin, ymin), (xmax, ymax), (0,0,255), 2) # box\n",
        "        for center_x,center_y in centers_old[id_obj].values():\n",
        "            cv2.circle(ROI, (center_x,center_y), 5,(0,0,255),-1) # center of box\n",
        "\n",
        "        #Drawing above the bounding-box the name of class recognized.\n",
        "        cv2.putText(img=ROI, text=id_obj+':'+str(np.round(conf[ix],2)),\n",
        "                    org= (xmin,ymin-10), fontFace=cv2.FONT_HERSHEY_TRIPLEX, fontScale=0.8, color=(0, 0, 255),thickness=1)\n",
        "\n",
        "\n",
        "\n",
        "    #drawing the number of people\n",
        "    cv2.putText(img=frame, text=f'Counts People in ROI: {count_p}',\n",
        "                org= (30,40), fontFace=cv2.FONT_HERSHEY_TRIPLEX,\n",
        "                fontScale=1.5, color=(255, 0, 0), thickness=1)\n",
        "\n",
        "    # Filtering tracks history\n",
        "    centers_old = filter_tracks(centers_old, patience)\n",
        "\n",
        "\n",
        "    #Drawing the ROI area\n",
        "    overlay = frame.copy()\n",
        "\n",
        "    # cv2.polylines(overlay, pts = area_roi, isClosed = True, color=(255, 0, 0),thickness=2)\n",
        "    # cv2.fillPoly(overlay, area_roi, (255,0,0))\n",
        "    # frame = cv2.addWeighted(overlay, alpha,frame , 1 - alpha, 0)\n",
        "\n",
        "    #Saving frames in a list\n",
        "    frames_list.append(frame)\n",
        "    #saving transformed frames in a output video formaat\n",
        "    output_video.write(frame)\n",
        "\n",
        "#Releasing the video\n",
        "output_video.release()\n",
        "\n",
        "\n",
        "# ####  pos processing\n",
        "# # Fixing video output codec to run in the notebook\\browser\n",
        "# if os.path.exists(output_path):\n",
        "#     os.remove(output_path)\n",
        "\n",
        "# subprocess.run(\n",
        "#     [\"ffmpeg\",  \"-i\", tmp_output_path,\"-crf\",\"18\",\"-preset\",\"veryfast\",\"-hide_banner\",\"-loglevel\",\"error\",\"-vcodec\",\"libx264\",output_path])\n",
        "# os.remove(tmp_output_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1e2c01e9c1cb4978bc4990a2a71828ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9056a3f7b85049d1b8e00f1c22cef334",
              "IPY_MODEL_2567e64471ca46dbb7a91c86062de2fa",
              "IPY_MODEL_de99875491f24a59947d9f4e431410a7"
            ],
            "layout": "IPY_MODEL_60cf70a9b5da4e1b99950825b01fe957"
          }
        },
        "2567e64471ca46dbb7a91c86062de2fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4bdb2047a64445cba281e903c3f99f2",
            "max": 172,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a49e03283cbf4cb9bafbbff132476a48",
            "value": 172
          }
        },
        "386dbcf420d44226a27fdd434e5820da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60cf70a9b5da4e1b99950825b01fe957": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80ded324aabe4dacbf266b18e39a01b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "818e1afafc214a31a013272e96717768": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9056a3f7b85049d1b8e00f1c22cef334": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_818e1afafc214a31a013272e96717768",
            "placeholder": "​",
            "style": "IPY_MODEL_80ded324aabe4dacbf266b18e39a01b4",
            "value": "100%"
          }
        },
        "a49e03283cbf4cb9bafbbff132476a48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4bdb2047a64445cba281e903c3f99f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de99875491f24a59947d9f4e431410a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec3965bff3ad48069a281d3b13e9a2af",
            "placeholder": "​",
            "style": "IPY_MODEL_386dbcf420d44226a27fdd434e5820da",
            "value": " 172/172 [00:16&lt;00:00, 11.67it/s]"
          }
        },
        "ec3965bff3ad48069a281d3b13e9a2af": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
